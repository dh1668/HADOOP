cd ..
ls
pwd
ls
vi README.MD
ls

-----------------------------------------------------------------------------
이론 

하둡 and 리눅스


● 빅 데이터 플랫폼의 이해 ●

- 빅데이터 플랫폼
- 빅데이터 플롯폼에 필요한 기능
- 하둡 빅데이터 플랫폼

 

1. 콜렉팅  = (수집목적)을 가지고 있기 때문에 하는것  		
웹,SNS데이터
시스템 로그 데이터  = PROTECT THE TECTION 
영역: 	ROBBOT , RSS Reader(기상청) , 
	OpenAPI(데이터를 암호화 알고리즘된 것을 받은것을 사용) , 
	Data Aggregator(프로토콜의 종류의 솔루션 수집)

2. 스토어  = 트렌드가 계속 빠르게 변화 , 데이터 최적화
대용량 데이터 저장소

★ 수집방법 < 2가지 타입으로 구분>
=> 1. BATCH : 일관처리 (일정시간을 두고) 
	MapReduce , SPARK

=> 2. RealTime : 실시간 ex) 버스 , IOT , 날씨
관련된 프로토콜이 있다. 
	Flume, KAfka, splunk
	<Avro , ... >

3. 어널시즈 <분석>  <= 머신러닝이 통계쪽을 대체함 ,알면 좋은 영역
' 분산/병렬 데이터 분석 '

Clustering (군집화) : 비슷해보이는 것들이 모이게 하고 구분하는것들
ex) 동양인들 외모가 비슷하기 때문에 언어 , 국적등으로 구분한다
= 데이터가 많이 필요하다 
< https://scikit-learn.org/stable/index.html > 참고
= 데이터가 불연속적임
=> 데이터의 정보를 모를때 사용해서 특성을 파악하는게 목적


Classification : 이미 분류 되어 있는 것들 = 구분이되어있어서 편함
ex) 빨간색 , 파란색은 구분되어있지만 흰색부분 잘구분해야한다는것
= ' 모델링 ' 한다고도 함
=> 새로운 데이터을 예측하기위한 분석기법


Regression : 시간의 결과 같은 데이터 근거를 통해 예측하기 위한것
ex)맥주가 여름에 많이 팔렸다 (여름마다 팔렸다는 그래프 같은걸로 표현)
= 데이터가 연속적임
= 하둡하는데 데이터 분석 

- 머신 러닝 : Data 분석 

Data ↓

1.지도 학습 : 처리하기 쉽다. 컴퓨터가 알고 있는 정보기 때문 
ex) 20년대 여성 금액20만원대 의상 => 마케팅 포인트


2.비지도 학습 : 처리하기 힘들고 어렵다. 이 영역이 굉장히 많음
ex)	사람 vs 침팬치 비유

3.강화 학습 :  


P.59 ~  : 데이터 분석하는 속도가 빨라진다
90% 이상의 데이터 결과를 뽑아낼 수 있다.
=>검증된 로직으로 <여기서 로직은 ' 머신러닝 '을 통해 구한다.>

진짜 시스템 엔니지어가 아닌이상 직업상 빅 데이터를 다룰일은 없다.


4. 리포팅/서칭 <디자이너영역 이라고 부르기도함>
다양한 뷰 제공

검색엔진 :
그래프/차트 :
User Define( UDF ) : 시각화된 것이 굉장히 많음
Query script :
ETL 엔진 :

----------------------------------------------------------------------------
2번째타임
HDFS 저장하는 공간


리눅스 터미널
start-dfs.sh
start-yarn.sh
hadoop fs -ls /
ls
cd /usr/sbin/hadoop-3.2.3
ls
find ./ -name user -print


실시간 분석 플랫폼 : splunk 도 있음

Hadoop MapReduce => 아마존에서도 쓰는거임

16 ~ 17장  피그 , 하이브 참고해보기

★- 데이터 마이닝/ 통계도구 :
오픈소스 : Mahout <분석> , R  <시각화>

★- 클러스터 관리 및 모니터링 : 여러대 쓰는것을 관리
Zookeeper, HUE , Cloumon 
=> yarn 다음단계가 Zookeeper

★- 데이터 Serialization : 데이터 빠르게 전송하기위해 <일렬로>
오픈소스 : Thrift , Avro , ProtoBuf

- 스트리밍 데이터 프로세싱 : 스트리밍 데이터 프로세싱기술
오픈소스 : Streaming DBMS , DW Appliance

- 분산처리 : 관리 기술, 분산 큐 기술 ,분산 캐시기능
오픈소스 : kafka , Zookeeper

- 데이터 분석 알고리즘 :


빅데이터 플랫폼 아키텍쳐 <사진참고>

빅데이터 플랫폼 아키텍쳐 사례 <사진참고>
< 관제 / 모니터링 > 프론트엔드 : 잘보이기에 고객과 제일 많이 접촉

< 분산 코디네이터 > 미들 티어 :  
객체데이터 캐시서버 , 일반데이터 캐시서버 , 분산미들웨어

=> 캐시 : 주머니에 넣는다는 개념 = 속도가 더 빨라진다 
	<가까울수록 더 빨라짐>
    밴드윅스 : 주머니가 크다는개념

< 분산 로그 관리 >백엔드 : 어려운 부분 쉬운 분야아님
★★★ -GFS 중요 : 구글에서 쳐보고 확인하기


하둡이란 ?
하둡파일시스템( HDFS,분산저장)

스케일 아웃 
- 서버의 수를 증가시켜 성능을 향상시키는 방식
- 증가된 서버들을 한 개의 시스템으로 인식시키기 위한 개념과 소프트웨어 필요
서버가 많을수록 비싸니깐 절약을 위해 쓰는방식이기도함


★빅데이터에 하둡을 적용하는 이유 :
애플리케이션/트랜잭션 로그 정보는 매우 크다.
=> 대용량 파일을 저장할 수있는 분산 파일 시스템 필요

I/O 집중적이면서 CPU도 많이 사용한다
=> 클러스터 구성을 통해 멀티 노드로 부하를 분산 처리하여야함
○ Map Reduce 란 ? I/O에서의 성능이 좀 낮은 기술

데이터베이스 특히 RDBMS는 하드웨어 추가시 성능향상이 선형적이지 않다.
=>장비를 증가시킬수록 성능이 선형적으로 향상되어야한다.

데이터베이스는 소프트웨어와 하드웨어가 비싸다.
=> 하둡,리눅스 무료, 하드웨어는 Intel기반의 표준플랫폼으로 저렴하게구성가능


--------------------------------------------------------------------------------
하둡 시스템 구성도 및 데이터 흐름도

데이터 워크워크플로우 관리
 >>>>>>>>>>>>>>>>>>>>>>
수집 > 저장/처리 > 분석 > 시각화

★하둡 에코시스템의 기본 구성

1. 하둡 부산 파일시스템과 맵리 듀스로 구성

2. 하둡 분산파일시스템  < HDFS >
      파일을 기본 64~ 128MB 단위로 나누어 분산 저장

      네임노드와 데이터노드로 분리 구성

3. 맵리듀스 Map reduce < ' 자바 '로 쓰임>
      대용량 데이터를 빠르고 안전하게 병렬처리 할 수 있도록 상용 하드웨어를
      이용한 분산 프로그래밍 모델

하둡 에코시스템 1.0 기준
	

Input = 실시간 SQL관리 <Tajo ,impala >

데이터분석 (Pig, Hive)  데이터마이닝 (Mahout)

메타데이터관리 ( HCatalog )

분산데이터 처리 ( MapReduce )

분산데이터 저장 ( HDFS )

비정형 데이터 수집 ( Flume )

정형 데이터 수집( Hiho )

---------------------------------------------------------------------------
★하둡 클러스트 구성

- 하나의 마스터와 다수의 슬레이브로 구성
- HDFS와 맵리듀스에서 명칭이 다름
- 하둡 에코시스템 1.0 기준


	  마스터	    슬레이브
HDFS       네임노드    데이터노드

맵리듀스   잡 트래커   태스크 트래커



★일반 분산 시스템과 차이점
1.접근성
-윈도우 PC 같은 컴퓨터 집합으로 구성된 클러스트에서 실행가능
- 마이크로소프트 AZURE와 같은 클라우드 컴퓨터 서비스에서 실행가능

2.견고성

3.확장가능성

4.용이성


UPS : 전원이 다운돼도 대신 전원역할을 해서 꺼지지않게 하는 유지장치




 " * " : Meta character ( = 모든 것 )



빅데이터 수집 기술

CHUKWA , SQOOP , ★ Flume

	WEBHDFS <<사이트

	Colum , ROW 는 필수적으로 알아야함

Flume 과 관련된 사이트 : 


CHUKWA : 하둡 프로젝트의 서브프로젝트로 진행 중인 오픈소스 프로젝트로 분산된 서버의 로그를 HDFS에 저장하고
	  하둡 맵리듀스를 이용해 로그 분석을 수행하는 Yahoo 의 프레임워크

특징: 범용적인 로그 수집과 로그 관리를 위한 솔루션으로 개발됐지만 하둡 클러스터와 로그와 
	       서버의 상태 정보 관리하는 기능 포함
	       하둡 이용해 작업수행시 로그를 보기위해 여러노드를 접속해야하는 불편함이 있는데 
		척와이용시 쉽게 로그 수집가능



OSI 7단계  <<구글검색

리눅스 
jps

hadoop fs -ls /
=>하둡 파일시스템 

cd /usr/sbin/hadoop-3.2.3

sudo apt install maven


---------------------------------------------------------------------
순서
cd

sudo apt install maven 먼저 터미널에


책 p.13 github.com/hadoop-book
들어가서
downloadzip 마우스클릭
리눅스 터미널로가서

cd
cd download
ls
hadoop 폴더 확인하고
cd .
mv hadoop-book-master.zip ../    <<전 디렉토리로 하둡파일이동
cd ..				전디렉토리로 이동
ls
mkdir hbook 		홈디렉토리에 hbook디렉토리 만들기
ls			디렉토리 만든거 확인
mv  hadoop-book-master.zip ./hbook/        ./ 은 현재디렉토리 위치
==> mv 이동시킬파일 ./ [현재디렉토리위치] hbook[옮길위치]

cd hbook		hbook 이동
ls
unzip hadoop-book-master.zip 	폴더풀기
ls				파일확인
cd hadoop-book-master 		원하는 디렉토리로 이동
ls
mvn  만하고 << 자바 다운로드 해체 ?

mvn package -DskipTests로 다시한번 해서 관리해제






















