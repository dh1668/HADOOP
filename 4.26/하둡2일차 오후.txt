하둡 시스템 구성도 및 데이터 흐름도

데이터 워크워크플로우 관리
 >>>>>>>>>>>>>>>>>>>>>>
수집 > 저장/처리 > 분석 > 시각화

★하둡 에코시스템의 기본 구성

1. 하둡 부산 파일시스템과 맵리 듀스로 구성


-------------------------------------------------------------------------------------------------
2. 하둡 분산파일시스템  < HDFS >
      파일을 기본 64~ 128MB 단위로 나누어 분산 저장

      네임노드와 데이터노드로 분리 구성



			HDFS 상세 메커니즘

	Data Write
	1.파일생성 정보 전송(첫번째 블록 크기만큼로컬에 쌓이면)
	2.블록을 보관할 노드목록 요청
	3.블록을 보관할 노드목록 제공
	4.목록 첫번째 노드에 쓰기
	5.복제
	6.완료

			  1 , 2 , 3
	하둡 클라이언트	  <<<<<<<	네임노드
			   6
	↓
	↓ 4번	

	데이터노드	>>>>	데이터노드       >>>>>	데이터노드
			5			5

--------------------------------------------------------------------------------------------------
3. 맵리듀스 < Map reduce >		< ' 자바 '로 쓰임>
      대용량 데이터를 빠르고 안전하게 병렬처리 할 수 있도록 상용 하드웨어를
      이용한 분산 프로그래밍 모델

하둡 에코시스템 1.0 기준
	

Input = 실시간 SQL관리 <Tajo ,impala >

데이터분석 (Pig, Hive)  데이터마이닝 (Mahout)

메타데이터관리 ( HCatalog )

분산데이터 처리 ( MapReduce )

분산데이터 저장 ( HDFS )

비정형 데이터 수집 ( Flume )

정형 데이터 수집( Hiho )

---------------------------------------------------------------------------
★하둡 클러스트 구성

- 하나의 마스터와 다수의 슬레이브로 구성
- HDFS와 맵리듀스에서 명칭이 다름
- 하둡 에코시스템 1.0 기준


	  마스터	    슬레이브
HDFS       네임노드    데이터노드

맵리듀스   잡 트래커   태스크 트래커



★일반 분산 시스템과 차이점
1.접근성
-윈도우 PC 같은 컴퓨터 집합으로 구성된 클러스트에서 실행가능
- 마이크로소프트 AZURE와 같은 클라우드 컴퓨터 서비스에서 실행가능

2.견고성

3.확장가능성

4.용이성


UPS : 전원이 다운돼도 대신 전원역할을 해서 꺼지지않게 하는 유지장치




 " * " : Meta character ( = 모든 것 )



빅데이터 수집 기술

CHUKWA , SQOOP , ★ Flume

	WEBHDFS <<사이트

	Colum(열) , ROW(행) 는 필수적으로 알아야함


1 . CHUKWA : 하둡 프로젝트의 서브프로젝트로 진행 중인 오픈소스 프로젝트로 분산된 서버의 로그를 HDFS에 저장하고
	  하둡 맵리듀스를 이용해 로그 분석을 수행하는 Yahoo 의 프레임워크

특징: 범용적인 로그 수집과 로그 관리를 위한 솔루션으로 개발됐지만 하둡 클러스터와 로그와 
	       서버의 상태 정보 관리하는 기능 포함
	       하둡 이용해 작업수행시 로그를 보기위해 여러노드를 접속해야하는 불편함이 있는데 
		척와이용시 쉽게 로그 수집가능



2. Flume : cloudera 에서 2010년에 공개한 오픈소스 로그 수집 프레임워크로서
	대량의 로그데이터를 효율적으로 수집 및 모니터링이 가능하고
	실시간 전송을 지원함

	Agent + Collect 구조의 이벤트 Data 수집이 목표

특징: - 높은 안정성, 가용성을 갖춘 로그관리용 오픈소스
       - 장애발생시에도 데이터를 잃지 않음 , 이벤트를 전달하는 것을
       계속 할 수 있는 Fail-Over
       - 자바로 구현되어 있기 때문에 다양한 운영체제에 설치가능


	- chukwa와 비슷하나 마스터 서버가 있어 수집 및 전송경로와
	방식을 동적으로 설정
	- 데이터 수집을 위한 다양한 데이터 플로우 토플로지를 구성할
	수 있고 , 마스터 서버에서 통합 관리 할 수 있는 웹페이지를
	제공할 뿐만 아니라, 이를 통해 설정을 쉽게 변경하거나 모니터링
	가능
	- 마스터 서버를 이중화하여 가용성이 높고, 자바로 구현되어
	있어 다양한 OS플랫폼에 포팅이 가능



Flume 과 관련된 사이트 : cloudera 






OSI 7단계  <<구글검색

리눅스 터미널 키고
jps

hadoop fs -ls /
=>하둡 파일시스템 

cd /usr/sbin/hadoop-3.2.3

sudo apt install maven


-----------------------------------------------------------------------
mvn 메이븐 : 아파치(웹서버) 랑 자바서버랑 연결하게 해주는 기능

mvn 순서
cd
mvn 치면 ↓ 치라고 나옴
sudo apt install maven 먼저 터미널에
Y

책 p.13 github.com/hadoop-book
들어가서
downloadzip 마우스클릭
리눅스 터미널로가서

cd
cd download
ls
hadoop 폴더 확인하고
cd .
mv hadoop-book-master.zip ../    <<전 디렉토리로 하둡파일이동
cd ..				전디렉토리로 이동
ls
mkdir hbook 		홈디렉토리에 hbook디렉토리 만들기
ls			디렉토리 만든거 확인
mv  hadoop-book-master.zip ./hbook/        ./ 은 현재디렉토리 위치
==> mv 이동시킬파일 ./ [현재디렉토리위치] hbook[옮길위치]

cd hbook		hbook 이동
ls
unzip hadoop-book-master.zip 	폴더풀기
ls				파일확인
cd hadoop-book-master 		원하는 디렉토리로 이동
ls
mvn  만하고 << 자바 다운로드 해체 ?

mvn package -DskipTests로 다시한번 해서 관리해제

cd ch02-mr-intro/
ls
vi pom.xml

hadoop target/ch02 (tab) : 여기폴더에는 파일이들어간다

mvn compile : 여기있는 소스만 컴파일한다

mvn install  : 여기있는 소스만 설치 <ch02-mr-intro> 위치에서하기
=> jar default 가 뜨면 
=> build success 뜰것임
=> 빨간색 jar 파일이 생길것임


----------------------------------------------------------------------
웹서버 하는 사람들은 나중에 파이썬 할 가능성이 높음


맵리듀스 정의 
분산화일 시스템 상에서빅 데이터의 분산 처리 부분을 담당
기능 적 또는 선언적 언어가 아니라 Key, Value 기반의 프로그램
맵 : ( k1, v1 ) list( k2 , v2 )


==> ★ 즉, 자바기능이 리눅스에선 맵핑, 리듀싱하는거임  


★ 맵리듀스 사례 > WordCount 프로그램
주어진 입력 파일에 들어있는 단어를 찾아내어 
그 빈도수를 계산하는 프로그램

1. 맵핑 : 분산처리 , (=카운팅하는거임) 
< (ex) deer 1개 , bear 1개 , River 1개 >


2. 리듀스 : ( k2 , list( v2 ) )   list ( k3, v3 )
리듀싱은 최종적으로 카운팅 (= 결과값)
< bear2개 , Car3개, Deer 2개 >


□맵리듀스 프로그래밍 방식
1. 자바언어
가장 raw level Programing
모든 기능 사용 가능하나 사전 지식 많이 필요하고 코드량도 가장 많음

2. 스트리밍 방식 언어
파이썬 ,펄 ,루비 등의 스크립트 사용
자바 사용하는 경우보다 조금 느림

3. 파이프 방식
소켓을 입출력 미디어로 사용하는 방식
C++ 언어 사용

4. Hive / Pig 등의 하이레벨 언어
MapReduce 에 대한 사전 이해없이 데이터 조작 가능한 하이레벨 언어
각 언어의 컴파일러를 통해 MapReduce 잡들로 변환되어 수행


- 맵리듀스 기본 동작 :
파일 용량에 따라서  리눅스 Cat 명령어로 확인해보면
↓밑의 같은 방식으로 출력됨
Part -r - 00000
Part -r - 00001





























