★하둡 web UI포트번호
데몬 		디폴트 포트번호		설정파라미터이름
hadoop cluster : 8088
hadoop namenode : 9870
hadoop datanode : 9864
hadoop status : 9868
hbase master status : 16010
hbase region server : 16030


---------------------------------------------------------------------------------
어제 실행시킨 jar명령어				↓/input 하둡으로 만든 디렉토리와 리눅스에서 복사한 README.txt  = WordCount할파일
hadoop jar target/WordCount-1.0-SNAPSHOT.jar WordCount /input/README.txt /output/WordCount
=>(jar 실행명령어)	 ( .jar = 실행시킬파일이름의 경로 )  ( 앞에 WordCount이름이름 무조건 같게, =프로그램명 )
( /input/README.txt 는 WordCount할 파일지정  )    (  /output/WordCount 는 결과를 지정시킬 디렉토리, 1번 실행할때마다 저장이름 바꿔야함 ) 	

어제 실행시킨 jar WordCount 단어와 카운트수
hadoop fs -cat /output/WordCount/part-r-00000


문서별로 위키피아에서 다운

4.27에 배운 			하둡명령어


	명령어				기능				비고	

hadoop fs -mkdir /input		input디렉토리 만들기		한번에한개씩만들어야함
<hadoop fs -mkdir /input/wex <<이렇게하면 에러남>

hadoop fs -rmr /output		output 디렉토리 삭제

hadoop fs -ls /output/...		output 디렉토리 view

hadoop fs -cat /output		output 디렉토리 파일내용 보기

hadoop fs -copyFromLocal /input	Input 디렉토리에 data파일 COPY	리눅스>>하눕

hadoop fs -copyToLocal /input	input에 있는 데이터를 복사해 리눅스에 붙여넣는다    하눕>>리눅스

hadoop fs -put * /input		*(=모든것,메타캐릭터) 모든데이터를 input에 넣는다

diff README.txt R.txt		내용물 다른거 가르쳐주는 용도 <vi 편집기로 내용다른것만 말해준다















-------------------------------------------------------------------------------------
<프로그래밍 소스 설명>
WordCount
임의 text 파일에서 단어별 출현 횟수 계산

WordCount2
단순한 텍스트 파일이 아니고 문서 내에 존재하는 문서ID가 있을경우 문서ID를
무시하고단어의 빈도수를 계산

TopN
문서 내에 단어의 출현 횟수가 많은 N개를 계산

Count Trigram
문서내에 3개의 단어가 연속 출현하는 회수를 계산 (TopN을 이용하여 빈도수 높은 10개 출력)

Count Citation
하나의 문서 내에 다른 문서들이 연결되어 있을 때 링크되는 문서들의 횟수를 처리
(구글의 페이지 랭크)

JoinDTitle2
분산 캐쉬를 이용하여 두 개의 조인 대상 중 하나의 크기가 작을때 효율적으로 처리
(분산 캐쉬는 작은 크기의 일기 전용파일(사전류)을 태스크의 작업 디렉토리에 복사해 주는 메커니즘

StirngSort
임의의 문자열로 구성된 파일을 알파벳 순으로 분리


----------------------------------시작---------------------------------------------------------------------------------------
★★★★★★★★★★★

Hive 란 ? 아파치 Hive란 Hadoop을 위한 데이터 웨어하우스 => 가공은 하지않고 원하는 종류의 데이터정보를 모아놓은것

Hive는 관계형 데이터베이스가 아니고 단지 메타데이터 정보를 유지

Hive는 테이블로서 빅데이터를 처리할 수 있게 하고 HiveQL 이라 불리는 스크립트 언어를
통하여 SQL 비슷하게 동작할 수 있게함 

★★★
특징:
- 테이블을 저장하기 위하여 '메타저장소'라고 불리는 데이터베이스를 사용함

- 스키마로 이루어진 Hive 테이블은 메타저장소에 있고 HDFS에 데이터를 저장함

- HIVE는 맵리듀스 잡을 HIVEQL 명령어로 변환함

- HIVE는 SQL과 비슷함

- HIVE 명령어를 사용하여 즉각적이고 쉽게 조회를 함


- 구조
스텝1 	:	명령어수행
스텝2	: 	hive 조회 계획
스텝3	:	맵리듀스 잡 수행

JDBC/ODBC 
web ui		sql할수있음
<사진참고>


=>요약
Hive <책 17장 >      = 분산데이터를 필요한 정보를 	"수집"		 한다는것
- 빅 데이터 처리 기술 중 분산 데이터웨어 하우스 기술
데이터웨어 하우스 :  Raw Data Lake >> Raw Data Warehouse 
=> 날것의 데이터를 필요한 정보만 수집하는것.(단 데이터가공은안함) => Data Analylist <무에서 유를 창조> 	

- HDFS에 저장된 대용량 데이터셋 분석 기능 제공
- 데이터 쿼리를 위해 SQL과 흡사한 HiveQL 언어 지원하며, hiveQL로 작성된
  스크립트는 하이브 컴파일러가 MapReduce 잡들로 변환
- 사용자는 MapReduce 프로그램을 몰라도 사용 가능 처리 성능 제한





★ PIG와 HIVE 차이


pig는 ETL일을 위한 최선의 선택 비정형데이터를 쉽게 재포맷하여 정의  (=양적인 측면에서 효율, 데이터 가리지않고 찾음)

PIg는 데이터를 옮기는 것과 재구성하는데 있어 효과

hive는 어떤 알려진 구조의 데이터를 조회할때 효과

hive는 데이터를 분석하는데 있어서 효과

hive는 성능에 있어서 어떠한것도 보장하지않음 hive의 간단한 조회도 수행시 시간이필요

-------------------------------------------------------------------------------------------------------------
Hive 문법					<거의 다 사진으로 찍어놓음>

★★ MYSQL 문법, NOSQL 약간 반반 섞은 문법이 많음



- Hive CLI
     전형적으로 hive 클라이언트는 즉각적으로 hive 서버에 연결
     $ hive
	hive > 


- Beeline   <JDBC/ODBC>
     새 명령어는 즉각적으로 Hive 서버2에 연결
     $ beeline
	Hive version 0.11.0-SNAPSHOT by Apache
	Beeline >


- Hive 테이블은 Hadoop 파일시스템의 비정형화된 데이터에 구조를 추가할 수 있게 함
  Hive 테이블에서 create table SQL 테이블과 같이 비슷하게 정의해서 사용
<사진참고>


- CREATE EXTERNAL : 외부터널

HIVE 매니지드 테이블같은 외부테이블을 테이블이 삭제 삭제(drop)되는 경우를
제외하고 /apps/hive/warehouse/salaries folder를 삭제하지 않음

db관련된 부분은 따로 리미테이션이 있다.

외부테이블 삭제되도 하둡 시스템에 남아있다.<중요>



- HIVE 테이블로 데이터적재

- 쿼리수행
테이블에서 SELECT를 한 테이블 상에서 WHERE를 사용함

-Hive 분할 <사진참고>
분할값에 의해 하위 디렉토리 생성

	/apps/hive/warehouse/employees
		/dept=hr/		
		/dept=hour/
   >>리눅스에서 employees 라는디렉토리에 mkdir hr 하위 디렉토리를 만든다고생각하면 편함

-HIVE 버킷 <사진참고>	: 나눈다

	효율적 조회 : 같은 버킷 컬럼에 있는 것을 조인을 행할때

	효율적 표본검출 : 데이터는 이미 작은 것으로 분리했기 때문에




- 스큐드 테이블 : 자주 나타나는 값을 갖고 있는 한개 의 칼럼 값을 찾는것


-데이터 정렬

	 HiveQL :
		  ORDER BY : 한개의 리듀서를 수행함으로서 데이터 정렬

		  SORT BY : 데이터 출력은 각 리듀서에 정렬

- 분배 사용하기
	
	
 	Hive는 ' 리듀서 ' 사이에서 분배되어진 로우(row) 와 그것에 의해 분배되어진 컬럼(column) 사용
 	=> 셔플링 위치쪽

	컬럼(column)에의해 똑같이 분배된 로우(raw)는 같은 리듀서로 옮김

	분배(Distibute)는 클클러스터링에 기록된 어떤 타입도 보장되지 않음


-한개의 파일로 저장


-맵 리듀스 특성 지정
	hive set 명령어로 맵리듀스 잡의 특성을 지정

	hiveconf 이용하여 매개변수 대치

- Hive 조인 전략<사진참고> 구글링해서 찾아보기 
	1. 셔플조인			데이터사이즈 배치 관계없이 작업	자원집중적, 느린조인형태가됨
	2. 맵(브로드캐스팅) 조인		매우 빠름 대테이블 연관		한개의 테이블 메모리 만에 맞추기위함
 	3. 정렬병합버킷 조인		어떤사이즈라도 빠름		데이터는 미리 버킷과 정렬해놓아야함
	조인별 의목적
	1조인 키값은 맵리듀스시 셔플되고 조인은 리듀스에서 수행

	2소테이블

	3맵퍼 효율조인

							
-Hive UDF (user defined Function)호출  		★★<현업에서 이걸 많이사용>
	
	○Hive 스크립터 내에서 UDF 호출하기 위한 작업
		-UDF 클래스를 포함하는 jar파일 등록
		-create temporary function 사용하여 별칭 정의
								defined 한정된					
								Function 기능				
								temporary : 일시적인
	
-멀티테이블 인서트 실행
	하이브 조회는 하나 또는 하나 이상의 맵리듀스 잡으로 변환되고 하둡클러스트에서 수행
		
- 뷰의 이해 

	SELECT문에 의해 정의되어 지고 테이블 과 같은 조회 결과를 처리함
	

	조회의 복잡합 제거하기 위해 뷰를 정의

	유저접근

	CREATE VIEW 이렇게 쓴다.

-뷰 사용


-인덱스 개요
 		1.table:  커스터머 		2. 하이브 메타스토어 		3. HDFS

		=> CREATE INDEX 이렇게쓴다



-오버( OVER ) 절


-윈도우 이용 

- HIVE 분석 함수

-HIVE 파일 형식
	하이브는 데이터를 저장하지 않음

	HDFS 상에 있는 데이터는 다음과 같은 형태의 테이블
	 - text file	콤마, 탭 또는 다른 범위를 정한 파일형태
 	 - sequence file	빠르게 역질렬화하여 직렬화된 키 /밸류 쌍을 hadoop 으로 저자ㅓㅇ
	 - RC file		컬럼으로 구성된 레코드 파일<전통적인 데이터베이스 로우(row) 형태에 비해>
         ★ - ORC file	상당한 양의 효율성 개선을 위해 최적화된 로우 형태
	 - SetDe		짧은 직렬 /역질렬화 시 레코드는 자바클래스로 쓰여진 형태로든 저장
	 - AvroSerDe	avro 스키마 사용시 파일을 읽고 쓰기에사용
	 - RegexSerDe	역질렬화 데이터시 정규 표현사용


-Hive ORC 파일 
최적화된 ORC파일은 HIVE 데이터를 저장하는데 고효율을 제공
	- 세개의 구성을 갖음 (stripe , Footer , Postscript)
	- Strpes로 명명된 row
	- 기본 stripe 크기 250mb 대용량임

-테이블 통계 계산
	hive는 메타저장소에 테이블과 분할 통계를 저장
	현재 hive에서 지원되고 있는 두가지 형태 존재


-------------------------------------------------------------------------------------------------------------------------
HIVE 성능 개선

- 벡터화
	한 개의 로우 ROW를 처리하는대신 1024개의 ROW를 처리할 수 있는 
	새로운 기능 프리미티브의 배열인 컬럼(column)으로 이루어짐

	전체의 컬럼인 벡터는 명령어  파이프라인과 캐시 사용


-테즈에서의 Hive 이해
	
	=> 정확도는 올라가지만 속도가 느릴것같다 => 그만큼 관계가 많이 이루어져있기때문에

		=> 하드시스템의 불필요한곳에 쓰는 것을 피한다


★★★★★★★★★★
HIVE 최적화 요령

- 분할, 버켓과 스큐를 이용하여 데이터를 분할

- 조인하기위해서 미리데이터정렬

- ORC 포멧을 사용

- 통상 조인시 정렬과 버킷사용

- 가능한 한 맵(브로드캐스팅) 조인 사용

- 지연을 제거하기위해 복사요소증가

- 테즈 이점을 이용

